# ollama-proxy
This intercepts Ollama-style API requests and transforms them into OpenAI-compatible requests for LM Studio.
